{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b5a3fc3-da6c-4b08-94cb-c11ebbd7e734",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ee7afbe-e853-4be3-a153-2a5c6778cc55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/executing/executing.py:713: DeprecationWarning: ast.Str is deprecated and will be removed in Python 3.14; use ast.Constant instead\n",
      "  right=ast.Str(s=sentinel),\n",
      "/opt/anaconda3/lib/python3.12/site-packages/executing/executing.py:713: DeprecationWarning: ast.Str is deprecated and will be removed in Python 3.14; use ast.Constant instead\n",
      "  right=ast.Str(s=sentinel),\n",
      "/opt/anaconda3/lib/python3.12/ast.py:587: DeprecationWarning: Attribute s is deprecated and will be removed in Python 3.14; use value instead\n",
      "  return Constant(*args, **kwargs)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/executing/executing.py:713: DeprecationWarning: ast.Str is deprecated and will be removed in Python 3.14; use ast.Constant instead\n",
      "  right=ast.Str(s=sentinel),\n",
      "/opt/anaconda3/lib/python3.12/ast.py:587: DeprecationWarning: Attribute s is deprecated and will be removed in Python 3.14; use value instead\n",
      "  return Constant(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Groceries data train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# df_test = pd.read_csv(\"Groceries data test.csv\")\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGroceries data train.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Groceries data train.csv'"
     ]
    }
   ],
   "source": [
    "# df_test = pd.read_csv(\"Groceries data test.csv\")\n",
    "df = pd.read_csv(\"Groceries data train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7764bbd2-033d-4e1b-959e-54a1d9044619",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data shape:\", df.shape)\n",
    "print(\"\\nFirst few rows of the dataset:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966c8348-1ddd-44a9-afdc-a9c1eb110729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for null or missing value\n",
    "print(\"\\nMissing values in each column:\")\n",
    "df_missing = pd.DataFrame((round(100 * (df.isnull().sum() / len(df.index)), 2)), columns=['missing'])\n",
    "df_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64762cbe-791f-4812-a813-1187fa20a8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['itemDescription'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13541723-9507-40c9-80dd-de21d9b66f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean itemDescription\n",
    "df['itemDescription'] = df['itemDescription'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91fa137-561f-4815-8046-2e1bf283c6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "basket_df = df.groupby(['Member_number', 'Date'])['itemDescription'].apply(list).reset_index()\n",
    "transactions = basket_df['itemDescription'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8201603-9638-4723-b27f-a2411fe95b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "basket_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19424aba-2c67-4254-8b88-597328169d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e82172-4078-4077-b427-9c9f3442c1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 20 items\n",
    "item_counts = Counter([item for sublist in transactions for item in sublist])\n",
    "print(item_counts.most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce12ab6-e6e0-4914-9613-cf6f30ce83d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Transaction Encoding for Apriori\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(transactions).transform(transactions)\n",
    "df_encoded = pd.DataFrame(te_ary, columns=te.columns_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624975e5-2493-4393-8708-45c2a334eccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec18994a-15c9-4948-be18-cf274c41739c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Frequent Itemset Mining with Apriori\n",
    "# Parameter tuning\n",
    "# min_support_values = [0.01, 0.02, 0.03, 0.05]\n",
    "min_support_values = [0.002,0.003,0.004, 0.005, 0.008]\n",
    "results = {}\n",
    "\n",
    "for min_support in min_support_values:\n",
    "    frequent_itemsets = apriori(df_encoded, min_support=min_support, use_colnames=True)\n",
    "    results[min_support] = frequent_itemsets\n",
    "    print(f\"\\nFrequent itemsets for min_support={min_support}:\")\n",
    "    # print(frequent_itemsets.sort_values('support', ascending=False).head(20))\n",
    "    print(frequent_itemsets.sort_values('support', ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ee8947-2a5c-4db3-82d5-bfaa6a6fb59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show frequent itemsets with more than one item\n",
    "for min_support in min_support_values:\n",
    "    fi = results[min_support]\n",
    "    multi_itemsets = fi[fi['itemsets'].apply(lambda x: len(x) > 1)]\n",
    "    print(f\"\\nFrequent itemsets with more than one item for min_support={min_support}:\")\n",
    "    print(multi_itemsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c89907-ef8f-4965-b4c4-9e45f4a48a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chosen_support = 0.002\n",
    "frequent_itemsets = results[chosen_support]\n",
    "\n",
    "# 5. Association Rule Mining\n",
    "min_confidence_values = [0.01, 0.05, 0.08, 0.09, 0.1]\n",
    "for min_conf in min_confidence_values:\n",
    "    rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=min_conf)\n",
    "    rules = rules.sort_values('lift', ascending=False)\n",
    "    print(f\"\\nAssociation Rules for min_confidence={min_conf}:\")\n",
    "    print(rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']].head(20))\n",
    "\n",
    "# Choose a min_confidence for visualization (e.g., 0.2)\n",
    "chosen_conf = 0.08\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=chosen_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e401519b-c3a3-43e7-80c6-98da4f33522a",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_itemsets = apriori(df_encoded, min_support=0.003, use_colnames=True)\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.08)\n",
    "rules = rules.sort_values(['confidence','lift'],ascending=[False,False])\n",
    "print(rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f50d93-28e0-41f6-b1dd-c8dfd5769165",
   "metadata": {},
   "source": [
    "Using min_support = 0.003 and min_confidence = 0.1, we identified 62 association rules. The strongest rule, (frankfurter) → (other vegetables), has a confidence of 10.7% and a lift of 1.15, indicating that customers who buy frankfurters are more likely to also buy other vegetables. Most rules involve “whole milk” or “other vegetables”, reflecting their popularity. While most lifts are modest, these rules provide actionable insights for product placement and cross-selling.\n",
    "\n",
    "Support: Most rules have support just above 0.003 (0.3%), meaning they occur in at least ~81 baskets out of 27,000. This is reasonable for actionable but not too rare patterns.\n",
    "\n",
    "Confidence: All rules have confidence above 10% (your chosen threshold), meaning the consequent appears at least 10% of the time when the antecedent is present.\n",
    "\n",
    "Lift: Most lift values are between 0.9 and 1.15. A lift > 1 means the rule is better than random; only a few rules (notably (frankfurter) → (other vegetables)) exceed 1.\n",
    "\n",
    "Other metrics (leverage, conviction, etc.): Most are close to zero, indicating weak but not spurious associations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddee0ba7-ace0-4adf-9ea7-b108a68fbd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add additional metrics (e.g., coverage, coverage ratio)\n",
    "rules['coverage'] = rules['antecedents'].apply(\n",
    "    lambda x: frequent_itemsets[frequent_itemsets['itemsets'] == x]['support'].values[0]\n",
    ")\n",
    "rules['zhang_metric'] = (rules['confidence'] - rules['consequent support']) / (1 - rules['consequent support'])\n",
    "\n",
    "# --------------------------------------------\n",
    "# 2. Display Top Rules by Different Metrics\n",
    "# --------------------------------------------\n",
    "def display_top_rules(rules, metric='lift', top_n=5):\n",
    "    return rules.sort_values(metric, ascending=False).head(top_n)\n",
    "\n",
    "print(\"\\nTop 5 Rules by Lift:\")\n",
    "display(display_top_rules(rules, 'lift'))\n",
    "\n",
    "print(\"\\nTop 5 Rules by Confidence:\")\n",
    "display(display_top_rules(rules, 'confidence'))\n",
    "\n",
    "print(\"\\nTop 5 Rules by Support:\")\n",
    "display(display_top_rules(rules, 'support'))\n",
    "\n",
    "# --------------------------------------------\n",
    "# 3. Visualize Rule Quality\n",
    "# --------------------------------------------\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(\n",
    "    x='confidence', \n",
    "    y='lift', \n",
    "    size='support', \n",
    "    hue='conviction', \n",
    "    data=rules,\n",
    "    alpha=0.7,\n",
    "    palette='viridis'\n",
    ")\n",
    "plt.title('Association Rules: Lift vs Confidence')\n",
    "plt.xlabel('Confidence')\n",
    "plt.ylabel('Lift')\n",
    "plt.axhline(1, linestyle='--', color='red')  # Lift=1 baseline\n",
    "plt.show()\n",
    "\n",
    "# --------------------------------------------\n",
    "# 4. Filter and Interpret Actionable Rules\n",
    "# --------------------------------------------\n",
    "# Filter rules with lift\n",
    "actionable_rules = rules.sort_values('lift', ascending=False)\n",
    "\n",
    "print(\"\\nActionable Rules:\")\n",
    "display(actionable_rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff864b5-484c-421b-81df-e204f8af1933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top N frequent itemsets\n",
    "top_n = 10\n",
    "top_itemsets = frequent_itemsets.sort_values('support', ascending=False).head(top_n)\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x='support', y=top_itemsets['itemsets'].astype(str), data=top_itemsets)\n",
    "plt.title(f'Top {top_n} Frequent Itemsets (min_support={chosen_support})')\n",
    "plt.xlabel('Support')\n",
    "plt.ylabel('Itemset')\n",
    "plt.show()\n",
    "\n",
    "# Support vs Confidence Scatter Plot\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(x='support', y='confidence', size='lift', data=rules, legend=False, alpha=0.7)\n",
    "plt.title('Support vs Confidence of Association Rules')\n",
    "plt.xlabel('Support')\n",
    "plt.ylabel('Confidence')\n",
    "plt.show()\n",
    "\n",
    "# Lift Distribution Histogram\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.histplot(rules['lift'], bins=20, kde=True)\n",
    "plt.title('Distribution of Lift Values')\n",
    "plt.xlabel('Lift')\n",
    "plt.ylabel('Frequency')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00d9ac7-9102-4075-9f8e-9d7c43ebbe43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_items(items, rules, top_n=5):\n",
    "    items_set = set(items)\n",
    "    recommendations = {}\n",
    "\n",
    "    for idx, row in rules.iterrows():\n",
    "        antecedent = set(row['antecedents'])\n",
    "        consequent = set(row['consequents'])\n",
    "\n",
    "        # If all antecedent items are in the basket and none of the consequent items are\n",
    "        if antecedent.issubset(items_set) and not consequent.issubset(items_set):\n",
    "            for item in consequent:\n",
    "                if item not in items_set:\n",
    "                    # Keep the highest confidence for each recommended item\n",
    "                    if item not in recommendations or recommendations[item] < row['confidence']:\n",
    "                        recommendations[item] = row['confidence']\n",
    "\n",
    "    # Sort recommendations by confidence, descending\n",
    "    recommended_list = sorted(recommendations.items(), key=lambda x: x[1], reverse=True)\n",
    "    return recommended_list[:top_n]\n",
    "\n",
    "# Example usage:\n",
    "# Suppose rules is your DataFrame of association rules\n",
    "# and the basket contains 'frankfurter' and 'sausage'\n",
    "basket = ['frankfurter', 'sausage']\n",
    "top_recs = recommend_items(basket, rules, top_n=3)\n",
    "print(\"Recommendations:\", top_recs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dfe3b8-9edc-4564-8b42-19ffb847278c",
   "metadata": {},
   "outputs": [],
   "source": [
    "basket = ['whole milk']\n",
    "top_recs = recommend_items(basket, rules, top_n=3)\n",
    "print(\"Recommendations:\", top_recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa2a584a-dfa2-4db4-8178-1b36cba77d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/executing/executing.py:713: DeprecationWarning: ast.Str is deprecated and will be removed in Python 3.14; use ast.Constant instead\n",
      "  right=ast.Str(s=sentinel),\n",
      "/opt/anaconda3/lib/python3.12/ast.py:587: DeprecationWarning: Attribute s is deprecated and will be removed in Python 3.14; use value instead\n",
      "  return Constant(*args, **kwargs)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/executing/executing.py:713: DeprecationWarning: ast.Str is deprecated and will be removed in Python 3.14; use ast.Constant instead\n",
      "  right=ast.Str(s=sentinel),\n",
      "/opt/anaconda3/lib/python3.12/ast.py:587: DeprecationWarning: Attribute s is deprecated and will be removed in Python 3.14; use value instead\n",
      "  return Constant(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'rules' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 13\u001b[0m\n\u001b[1;32m      9\u001b[0m     rules_to_save\u001b[38;5;241m.\u001b[39mto_csv(filename, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRules saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m save_rules_to_csv(rules)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rules' is not defined"
     ]
    }
   ],
   "source": [
    "def save_rules_to_csv(rules, filename='association_rules.csv'):\n",
    "    # Convert frozensets in 'antecedents' and 'consequents' to strings for CSV readability\n",
    "    rules_to_save = rules.copy()\n",
    "    if 'antecedents' in rules_to_save.columns:\n",
    "        rules_to_save['antecedents'] = rules_to_save['antecedents'].apply(lambda x: ', '.join(list(x)))\n",
    "    if 'consequents' in rules_to_save.columns:\n",
    "        rules_to_save['consequents'] = rules_to_save['consequents'].apply(lambda x: ', '.join(list(x)))\n",
    "\n",
    "    rules_to_save.to_csv(filename, index=False)\n",
    "    print(f\"Rules saved to {filename}\")\n",
    "\n",
    "\n",
    "save_rules_to_csv(rules)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1e5cd8-d806-405b-87ef-38e2458ed311",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
